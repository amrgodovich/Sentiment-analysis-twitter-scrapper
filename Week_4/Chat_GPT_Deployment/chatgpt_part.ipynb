{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "id": "lxL_1MZipBBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "Dsp3nR3F_jQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-Zfli_rq4wF7JGxsM6GGZdtKFVZa_d5bIjkILjTON-rT3BlbkFJuxpDwkRwp7N9NF2in2uJT-pUt4hMkCFjR90zb2gC8A\""
      ],
      "metadata": {
        "id": "pOin6D8N5Mwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Change the model to GPT-3.5-turbo\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a haiku about recursion in programming.\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(completion.choices[0].message)\n"
      ],
      "metadata": {
        "id": "j0JOhoEL_dDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}