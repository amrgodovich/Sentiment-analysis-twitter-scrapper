{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Twitter_Data/Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna(subset=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(data[data['category']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0\n",
       "8  with upcoming election india saga going import...       1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category']=data['category'].replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    72249\n",
       "category      72250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['category']==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Twitter_Data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 107760 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  107758 non-null  object \n",
      " 1   category    107760 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Load the necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk as nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162972</th>\n",
       "      <td>engine growth modi unveils indias first 12000 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162973</th>\n",
       "      <td>modi promised 2014 lok sabha elections that be...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  label\n",
       "0       when modi promised “minimum government maximum...    0.0\n",
       "2       what did just say vote for modi  welcome bjp t...    1.0\n",
       "3       asking his supporters prefix chowkidar their n...    1.0\n",
       "4       answer who among these the most powerful world...    1.0\n",
       "8       with upcoming election india saga going import...    1.0\n",
       "...                                                   ...    ...\n",
       "162972  engine growth modi unveils indias first 12000 ...    1.0\n",
       "162973  modi promised 2014 lok sabha elections that be...    1.0\n",
       "162975  why these 456 crores paid neerav modi not reco...    0.0\n",
       "162976  dear rss terrorist payal gawar what about modi...    0.0\n",
       "162979  have you ever listen about like gurukul where ...    1.0\n",
       "\n",
       "[107760 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.rename(columns={'category': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.rename(columns={'clean_text': 'text'})\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to remove non-English characters, handling NaN and other data types\n",
    "def remove_non_english(text):\n",
    "    \"\"\"\n",
    "    Removes non-English characters from a text string, handling NaN and other data types.\n",
    "\n",
    "    Args:\n",
    "        text: The input text string.\n",
    "\n",
    "    Returns:\n",
    "        The text string with non-English characters removed.\n",
    "    \"\"\"\n",
    "    # Convert to string and replace NaN with an empty string\n",
    "    text = str(text)\n",
    "    text = text.replace('nan', '')  # Replace NaN values with an empty string\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "# Assuming you have your data in a pandas DataFrame called 'data' with a column 'Text'\n",
    "# Apply the function to the 'Text' column\n",
    "data['text'] = data['text'].apply(remove_non_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "stopwords_En = nltk.corpus.stopwords.words('english')\n",
    "#Expectation no and not\n",
    "stopwords_En.remove('no')\n",
    "stopwords_En.remove('not')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize #import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Check if text is a string before processing\n",
    "    if isinstance(text, str):\n",
    "        text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "        tokens = word_tokenize(text)\n",
    "        text = \" \".join([wn.lemmatize(word) for word in tokens if word not in stopwords_En])\n",
    "        return text\n",
    "    # If text is not a string (e.g., float), return it as is or handle it appropriately\n",
    "    else:\n",
    "        return str(text)  # or return \"\" or handle NaN values differently\n",
    "\n",
    "data['cleaned_Text'] = data['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Twitter_Data/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107760, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1729029343950, experiment_id='0', last_update_time=1729033419636, lifecycle_stage='active', name='Sentiment_analysis_DEPI', tags={}>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment(\"Sentiment_analysis_DEPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 12/12 [00:02<00:00,  5.16it/s] \n"
     ]
    }
   ],
   "source": [
    "logged_model = 'runs:/fbd8d80ce1514764b6301ee1058a5e74/neural_network_classifier_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "def load_sentiment_model():\n",
    "    model_path = '../Amazon_review_sent_analysis model.h5'\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "    model = load_model(model_path)\n",
    "    return model\n",
    "mymodel=load_sentiment_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Encode the input text using the BERT model\n",
    "    embedding = model_bert.encode([text])\n",
    "\n",
    "    # Make prediction using the loaded model\n",
    "    # prob = model.predict(embedding)[0][0]  # Get the probability score\n",
    "    prob2 = mymodel.predict(embedding)[0][0]  # Get the probability score\n",
    "\n",
    "\n",
    "    # Determine the label based on the probability\n",
    "    # label1 = \"Positive\" if prob > 0.5 else \"Negative\"\n",
    "    label2 = \"Positive\" if prob2 > 0.5 else \"Negative\"\n",
    "\n",
    "    # Return both the label and probability\n",
    "    return label2,  prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "('Negative', 0.007748674)\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "# sample=data['cleaned_Text'][0]\n",
    "sample='love'\n",
    "xx=predict_sentiment(sample)\n",
    "print(xx)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised minimum government maximum ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>modi promised minimum government maximum gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>say vote modi welcome bjp told rahul main camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asking supporter prefix chowkidar name modi gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>answer among powerful world leader today trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>upcoming election india saga going important p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  when modi promised minimum government maximum ...    0.0   \n",
       "2  what did just say vote for modi  welcome bjp t...    1.0   \n",
       "3  asking his supporters prefix chowkidar their n...    1.0   \n",
       "4  answer who among these the most powerful world...    1.0   \n",
       "8  with upcoming election india saga going import...    1.0   \n",
       "\n",
       "                                        cleaned_Text  \n",
       "0  modi promised minimum government maximum gover...  \n",
       "2  say vote modi welcome bjp told rahul main camp...  \n",
       "3  asking supporter prefix chowkidar name modi gr...  \n",
       "4  answer among powerful world leader today trump...  \n",
       "8  upcoming election india saga going important p...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization & Padding \n",
      " modi promised minimum government maximum goverce expected begin difficult job reforming state take year get justice state not business exit psus temple\n",
      "\n",
      "After Tokenization & Padding \n",
      " [   1  278  668   30 1804  681  799 1676  871   60  102   43   15   26\n",
      "  926  102    3  397 3664 4747 1142    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 5000\n",
    "max_len=50\n",
    "\n",
    "def tokenize_pad_sequences(text):\n",
    "    '''\n",
    "    This function tokenize the input text into sequnences of intergers and then\n",
    "    pad each sequence to the same length\n",
    "    '''\n",
    "    # Text tokenization\n",
    "    tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    # Transforms text to a sequence of integers\n",
    "    X = tokenizer.texts_to_sequences(text)\n",
    "    # Pad sequences to the same length\n",
    "    X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "    # return sequences\n",
    "    return X, tokenizer\n",
    "\n",
    "print('Before Tokenization & Padding \\n', data['cleaned_Text'][0])\n",
    "X, tokenizer = tokenize_pad_sequences(data['cleaned_Text'])\n",
    "print('\\nAfter Tokenization & Padding \\n', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set -> (64656, 50) (64656, 2)\n",
      "Validation Set -> (21552, 50) (21552, 2)\n",
      "Test Set -> (21552, 50) (21552, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = pd.get_dummies(data['label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "print('Train Set ->', X_train.shape, y_train.shape)\n",
    "print('Validation Set ->', X_val.shape, y_val.shape)\n",
    "print('Test Set ->', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.optimizers import SGD\n",
    "from keras import datasets\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "\n",
    "from keras import losses\n",
    "\n",
    "vocab_size = 5000\n",
    "embedding_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.01  # Reduced learning rate for stability\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "\n",
    "# Create SGD optimizer with reduced learning rate and higher momentum\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True)))  # Add return_sequences for stacking\n",
    "model.add(Bidirectional(LSTM(32)))  # Add another LSTM layer for deeper learning\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, \n",
    "               metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Train model\n",
    "\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, y_train,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))\n",
    "\n",
    "model.save('lstm.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 33s 25ms/step - loss: 0.6355 - accuracy: 0.6694 - precision_1: 0.6694 - recall_1: 0.6694 - val_loss: 0.6320 - val_accuracy: 0.6723 - val_precision_1: 0.6723 - val_recall_1: 0.6723\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.6337 - accuracy: 0.6700 - precision_1: 0.6700 - recall_1: 0.6700 - val_loss: 0.6313 - val_accuracy: 0.6723 - val_precision_1: 0.6723 - val_recall_1: 0.6723\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 23s 22ms/step - loss: 0.6327 - accuracy: 0.6700 - precision_1: 0.6700 - recall_1: 0.6700 - val_loss: 0.6309 - val_accuracy: 0.6723 - val_precision_1: 0.6723 - val_recall_1: 0.6723\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.6318 - accuracy: 0.6700 - precision_1: 0.6700 - recall_1: 0.6700 - val_loss: 0.6296 - val_accuracy: 0.6723 - val_precision_1: 0.6723 - val_recall_1: 0.6723\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.6302 - accuracy: 0.6700 - precision_1: 0.6700 - recall_1: 0.6700 - val_loss: 0.6282 - val_accuracy: 0.6723 - val_precision_1: 0.6723 - val_recall_1: 0.6723\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.6263 - accuracy: 0.6700 - precision_1: 0.6700 - recall_1: 0.6700 - val_loss: 0.6199 - val_accuracy: 0.6723 - val_precision_1: 0.6723 - val_recall_1: 0.6723\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.5977 - accuracy: 0.6798 - precision_1: 0.6798 - recall_1: 0.6798 - val_loss: 0.5371 - val_accuracy: 0.7325 - val_precision_1: 0.7325 - val_recall_1: 0.7325\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 24s 23ms/step - loss: 0.4542 - accuracy: 0.7828 - precision_1: 0.7828 - recall_1: 0.7828 - val_loss: 0.4546 - val_accuracy: 0.7788 - val_precision_1: 0.7788 - val_recall_1: 0.7788\n",
      "Epoch 9/20\n",
      "1011/1011 [==============================] - 24s 24ms/step - loss: 0.3652 - accuracy: 0.8412 - precision_1: 0.8412 - recall_1: 0.8412 - val_loss: 0.3291 - val_accuracy: 0.8627 - val_precision_1: 0.8627 - val_recall_1: 0.8627\n",
      "Epoch 10/20\n",
      "1011/1011 [==============================] - 24s 23ms/step - loss: 0.3125 - accuracy: 0.8707 - precision_1: 0.8707 - recall_1: 0.8707 - val_loss: 0.3129 - val_accuracy: 0.8731 - val_precision_1: 0.8731 - val_recall_1: 0.8731\n",
      "Epoch 11/20\n",
      "1011/1011 [==============================] - 24s 23ms/step - loss: 0.2848 - accuracy: 0.8862 - precision_1: 0.8862 - recall_1: 0.8862 - val_loss: 0.3132 - val_accuracy: 0.8681 - val_precision_1: 0.8681 - val_recall_1: 0.8681\n",
      "Epoch 12/20\n",
      "1011/1011 [==============================] - 24s 24ms/step - loss: 0.2596 - accuracy: 0.8994 - precision_1: 0.8994 - recall_1: 0.8994 - val_loss: 0.2833 - val_accuracy: 0.8890 - val_precision_1: 0.8890 - val_recall_1: 0.8890\n",
      "Epoch 13/20\n",
      "1011/1011 [==============================] - 24s 24ms/step - loss: 0.2478 - accuracy: 0.9042 - precision_1: 0.9042 - recall_1: 0.9042 - val_loss: 0.3390 - val_accuracy: 0.8673 - val_precision_1: 0.8673 - val_recall_1: 0.8673\n",
      "Epoch 14/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.2363 - accuracy: 0.9085 - precision_1: 0.9085 - recall_1: 0.9085 - val_loss: 0.2669 - val_accuracy: 0.8937 - val_precision_1: 0.8937 - val_recall_1: 0.8937\n",
      "Epoch 15/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.2244 - accuracy: 0.9141 - precision_1: 0.9141 - recall_1: 0.9141 - val_loss: 0.2641 - val_accuracy: 0.8956 - val_precision_1: 0.8956 - val_recall_1: 0.8956\n",
      "Epoch 16/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.2157 - accuracy: 0.9192 - precision_1: 0.9192 - recall_1: 0.9192 - val_loss: 0.2627 - val_accuracy: 0.8932 - val_precision_1: 0.8932 - val_recall_1: 0.8932\n",
      "Epoch 17/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.2092 - accuracy: 0.9198 - precision_1: 0.9198 - recall_1: 0.9198 - val_loss: 0.3101 - val_accuracy: 0.8818 - val_precision_1: 0.8818 - val_recall_1: 0.8818\n",
      "Epoch 18/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.2042 - accuracy: 0.9237 - precision_1: 0.9237 - recall_1: 0.9237 - val_loss: 0.2549 - val_accuracy: 0.8982 - val_precision_1: 0.8982 - val_recall_1: 0.8982\n",
      "Epoch 19/20\n",
      "1011/1011 [==============================] - 23s 23ms/step - loss: 0.1946 - accuracy: 0.9275 - precision_1: 0.9275 - recall_1: 0.9275 - val_loss: 0.2619 - val_accuracy: 0.8969 - val_precision_1: 0.8969 - val_recall_1: 0.8969\n",
      "Epoch 20/20\n",
      "1011/1011 [==============================] - 24s 23ms/step - loss: 0.1919 - accuracy: 0.9285 - precision_1: 0.9285 - recall_1: 0.9285 - val_loss: 0.2555 - val_accuracy: 0.8992 - val_precision_1: 0.8992 - val_recall_1: 0.8992\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, \n",
    "               metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Train model\n",
    "\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, y_train,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy  : 0.8995\n",
      "Precision : 0.8995\n",
      "Recall    : 0.8995\n",
      "F1 Score  : 0.8995\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 12/12 [00:08<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import mlflow\n",
    "\n",
    "logged_model = 'runs:/f8b0e6e1aee14f4f89c1b68e3e56bfc8/lstm'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(text):\n",
    "    '''Function to predict sentiment class of the passed text'''\n",
    "    \n",
    "    sentiment_classes = ['Negative', 'Positive']\n",
    "    max_len=50\n",
    "    \n",
    "    # Transforms text to a sequence of integers using a tokenizer object\n",
    "    xt = tokenizer.texts_to_sequences(text)\n",
    "    # Pad sequences to the same length\n",
    "    xt = pad_sequences(xt, padding='post', maxlen=max_len)\n",
    "    # Do the prediction using the loaded model\n",
    "    yt = loaded_model.predict(xt).argmax(axis=1)\n",
    "    # Print the predicted sentiment\n",
    "    print('The predicted sentiment is', sentiment_classes[yt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(text):\n",
    "    '''Function to predict sentiment class of the passed text and return probability'''\n",
    "    \n",
    "    sentiment_classes = ['Negative', 'Positive']\n",
    "    max_len = 50\n",
    "    \n",
    "    # Transforms text to a sequence of integers using a tokenizer object\n",
    "    xt = tokenizer.texts_to_sequences(text)\n",
    "    # Pad sequences to the same length\n",
    "    xt = pad_sequences(xt, padding='post', maxlen=max_len)\n",
    "    \n",
    "    # Do the prediction using the loaded model\n",
    "    probabilities = loaded_model.predict(xt)\n",
    "    \n",
    "    # Get the predicted class (with highest probability)\n",
    "    predicted_class = probabilities.argmax(axis=1)[0]\n",
    "    \n",
    "    # Print the predicted sentiment and the corresponding probability\n",
    "    predicted_sentiment = sentiment_classes[predicted_class]\n",
    "    predicted_probability = probabilities[0][predicted_class]\n",
    "    \n",
    "    print(f\"The predicted sentiment is '{predicted_sentiment}' with probability {predicted_probability:.4f}\")\n",
    "    \n",
    "    return predicted_sentiment, predicted_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "The predicted sentiment is Positive\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005082759"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class(['I love india'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
